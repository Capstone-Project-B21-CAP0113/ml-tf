{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Text Classification Notebook"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install tensorflow\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install PySastrawi\n",
    "!pip install sklearn\n",
    "!pip install keras-tuner"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning related imports\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and generic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import string\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2852, 27)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  perselisihan  \\\n",
       "0  mohon bantuannya untuk menormalkan sistem di l...             0   \n",
       "1  ass pak gubsaya perangkat desa karangsari kec ...             1   \n",
       "2  selamat sore bapak gubernur atau yang mewakili...             0   \n",
       "3  assalamualaikum pak gub saya pengurus paguyuba...             0   \n",
       "4  lapor saya okada arle sandi email  okadaarlegm...             0   \n",
       "\n",
       "   infrastruktur  pemerintah  kesehatan  teknologi  administrasi  fasilitas  \\\n",
       "0              0           0          0          1             0          0   \n",
       "1              0           0          0          0             0          0   \n",
       "2              1           0          0          0             0          0   \n",
       "3              0           1          0          0             0          0   \n",
       "4              0           0          1          0             0          0   \n",
       "\n",
       "   lingkungan  ketertiban  ...  air  pendidikan  kebersihan  sosial  wisata  \\\n",
       "0           0           0  ...    0           0           0       0       0   \n",
       "1           0           0  ...    0           0           0       0       0   \n",
       "2           0           0  ...    0           0           0       0       0   \n",
       "3           0           0  ...    0           0           0       0       0   \n",
       "4           0           0  ...    0           0           0       0       0   \n",
       "\n",
       "   sara  pencurian  korupsi  bbm  keuangan  \n",
       "0     0          0        0    0         0  \n",
       "1     0          0        0    0         0  \n",
       "2     0          0        0    0         0  \n",
       "3     0          0        0    0         0  \n",
       "4     0          0        0    0         0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>perselisihan</th>\n      <th>infrastruktur</th>\n      <th>pemerintah</th>\n      <th>kesehatan</th>\n      <th>teknologi</th>\n      <th>administrasi</th>\n      <th>fasilitas</th>\n      <th>lingkungan</th>\n      <th>ketertiban</th>\n      <th>...</th>\n      <th>air</th>\n      <th>pendidikan</th>\n      <th>kebersihan</th>\n      <th>sosial</th>\n      <th>wisata</th>\n      <th>sara</th>\n      <th>pencurian</th>\n      <th>korupsi</th>\n      <th>bbm</th>\n      <th>keuangan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mohon bantuannya untuk menormalkan sistem di l...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ass pak gubsaya perangkat desa karangsari kec ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>selamat sore bapak gubernur atau yang mewakili...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>assalamualaikum pak gub saya pengurus paguyuba...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lapor saya okada arle sandi email  okadaarlegm...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 27 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Load dataset\n",
    "filepath = os.getcwd()\n",
    "datasetpath =  os.path.join(filepath, \"cleaned_data\", \"laporanencoded.csv\")\n",
    "\n",
    "# Github URL for dataset when used in Google Colab\n",
    "github_url = \"https://raw.githubusercontent.com/Capstone-Project-B21-CAP0113/ml-tf/main/laporan/cleaned_data/laporanencoded.csv\"\n",
    "\n",
    "laporan = pd.read_csv(datasetpath, encoding=\"ISO-8859-1\")\n",
    "# Print dataset shape\n",
    "print(laporan.shape)\n",
    "# Print dataset head\n",
    "laporan.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "perselisihan: 16\ninfrastruktur: 353\npemerintah: 68\nkesehatan: 80\nteknologi: 23\nadministrasi: 693\nfasilitas: 73\nlingkungan: 114\nketertiban: 87\nlistrik: 43\nbahaya: 22\nlainnya: 139\npungli: 106\nilegal: 47\nlalulintas: 42\nbencana: 58\nair: 85\npendidikan: 134\nkebersihan: 9\nsosial: 181\nwisata: 13\nsara: 7\npencurian: 6\nkorupsi: 39\nbbm: 1\nkeuangan: 82\n"
     ]
    }
   ],
   "source": [
    "# Split text and labels\n",
    "label_list = [\n",
    "    \"perselisihan\",\n",
    "    \"infrastruktur\",\n",
    "    \"pemerintah\",\n",
    "    \"kesehatan\",\n",
    "    \"teknologi\",\n",
    "    \"administrasi\",\n",
    "    \"fasilitas\",\n",
    "    \"lingkungan\",\n",
    "    \"ketertiban\",\n",
    "    \"listrik\",\n",
    "    \"bahaya\",\n",
    "    \"lainnya\",\n",
    "    \"pungli\",\n",
    "    \"ilegal\",\n",
    "    \"lalulintas\",\n",
    "    \"bencana\",\n",
    "    \"air\",\n",
    "    \"pendidikan\",\n",
    "    \"kebersihan\",\n",
    "    \"sosial\",\n",
    "    \"wisata\",\n",
    "    \"sara\",\n",
    "    \"pencurian\",\n",
    "    \"korupsi\",\n",
    "    \"bbm\",\n",
    "    \"keuangan\"\n",
    "] \n",
    "x = laporan[\"text\"]\n",
    "y = laporan[label_list]\n",
    "\n",
    "# Print number of element in each category ( one element can have many label since it's a multi label classification )\n",
    "for i in label_list:\n",
    "    print(\"{}: {}\".format(i, (laporan[i] == 1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    mohon bantuannya untuk menormalkan sistem di l...\n",
       "1    ass pak gubsaya perangkat desa karangsari kec ...\n",
       "2    selamat sore bapak gubernur atau yang mewakili...\n",
       "3    assalamualaikum pak gub saya pengurus paguyuba...\n",
       "4    lapor saya okada arle sandi email  okadaarlegm...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Text head\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   perselisihan  infrastruktur  pemerintah  kesehatan  teknologi  \\\n",
       "0             0              0           0          0          1   \n",
       "1             1              0           0          0          0   \n",
       "2             0              1           0          0          0   \n",
       "3             0              0           1          0          0   \n",
       "4             0              0           0          1          0   \n",
       "\n",
       "   administrasi  fasilitas  lingkungan  ketertiban  listrik  ...  air  \\\n",
       "0             0          0           0           0        0  ...    0   \n",
       "1             0          0           0           0        0  ...    0   \n",
       "2             0          0           0           0        0  ...    0   \n",
       "3             0          0           0           0        0  ...    0   \n",
       "4             0          0           0           0        0  ...    0   \n",
       "\n",
       "   pendidikan  kebersihan  sosial  wisata  sara  pencurian  korupsi  bbm  \\\n",
       "0           0           0       0       0     0          0        0    0   \n",
       "1           0           0       0       0     0          0        0    0   \n",
       "2           0           0       0       0     0          0        0    0   \n",
       "3           0           0       0       0     0          0        0    0   \n",
       "4           0           0       0       0     0          0        0    0   \n",
       "\n",
       "   keuangan  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>perselisihan</th>\n      <th>infrastruktur</th>\n      <th>pemerintah</th>\n      <th>kesehatan</th>\n      <th>teknologi</th>\n      <th>administrasi</th>\n      <th>fasilitas</th>\n      <th>lingkungan</th>\n      <th>ketertiban</th>\n      <th>listrik</th>\n      <th>...</th>\n      <th>air</th>\n      <th>pendidikan</th>\n      <th>kebersihan</th>\n      <th>sosial</th>\n      <th>wisata</th>\n      <th>sara</th>\n      <th>pencurian</th>\n      <th>korupsi</th>\n      <th>bbm</th>\n      <th>keuangan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 26 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Label head\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-7-7f4537c43ddc>:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  x[i] = stopword.remove(x[i])\n<ipython-input-7-7f4537c43ddc>:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  x[i] = stemmer.stem(x[i])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    bantu normal sistem lpse kabupaten demak mana ...\n",
       "1    ass gubsaya perangkat desa karangsari kec kara...\n",
       "2    selamat sore gubernur mewakilisaya ahmad rofiq...\n",
       "3    assalamualaikum gub urus paguyuban dagang puja...\n",
       "4    lapor okada arle sandi email okadaarlegmailcom...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Remove stopwords and stem words using Sastrawi\n",
    "stemmer_factory = StemmerFactory()\n",
    "stemmer = stemmer_factory.create_stemmer()\n",
    "\n",
    "stopword_factory = StopWordRemoverFactory()\n",
    "stopword = stopword_factory.create_stop_word_remover()\n",
    "\n",
    "for i in range(len(x)):\n",
    "    x[i] = stopword.remove(x[i])\n",
    "    x[i] = stemmer.stem(x[i])\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad text\n",
    "vocab_size = 2000\n",
    "embedding_dim = 16\n",
    "max_length = 300\n",
    "trunc_type = \"post\"\n",
    "oov_token = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(x)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "72\n18\n"
     ]
    }
   ],
   "source": [
    "# Shuffle, batch and separate data into train, dev and test\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 32\n",
    "DATASET_SIZE = len(x)\n",
    "\n",
    "\n",
    "tx = tf.convert_to_tensor(padded)\n",
    "ty = tf.convert_to_tensor(y)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tx, ty))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "train_set = dataset.take(int(0.8 * len(dataset)))\n",
    "test_set = dataset.skip(int(0.8 * len(dataset)))\n",
    "test_set = dataset.take(int(0.2 * len(dataset))) \n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, None, 128)         256000    \n_________________________________________________________________\nbidirectional (Bidirectional (None, None, 256)         263168    \n_________________________________________________________________\ndropout (Dropout)            (None, None, 256)         0         \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 128)               164352    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                8256      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_2 (Dense)              (None, 26)                858       \n=================================================================\nTotal params: 694,714\nTrainable params: 694,714\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, 128),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(26, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "72/72 [==============================] - 99s 1s/step - loss: 0.1272 - accuracy: 0.2331 - val_loss: 0.1166 - val_accuracy: 0.2361\n",
      "Epoch 2/200\n",
      "72/72 [==============================] - 76s 1s/step - loss: 0.1256 - accuracy: 0.2426 - val_loss: 0.1158 - val_accuracy: 0.2448\n",
      "Epoch 3/200\n",
      "72/72 [==============================] - 76s 1s/step - loss: 0.1202 - accuracy: 0.2873 - val_loss: 0.1075 - val_accuracy: 0.3524\n",
      "Epoch 4/200\n",
      "72/72 [==============================] - 75s 1s/step - loss: 0.1178 - accuracy: 0.3147 - val_loss: 0.1030 - val_accuracy: 0.3368\n",
      "Epoch 5/200\n",
      "72/72 [==============================] - 75s 1s/step - loss: 0.1134 - accuracy: 0.3424 - val_loss: 0.1007 - val_accuracy: 0.3438\n",
      "Epoch 6/200\n",
      "72/72 [==============================] - 74s 1s/step - loss: 0.1098 - accuracy: 0.3368 - val_loss: 0.0954 - val_accuracy: 0.3507\n",
      "Epoch 7/200\n",
      "72/72 [==============================] - 76s 1s/step - loss: 0.1061 - accuracy: 0.3451 - val_loss: 0.0954 - val_accuracy: 0.3351\n",
      "Epoch 8/200\n",
      "72/72 [==============================] - 76s 1s/step - loss: 0.1040 - accuracy: 0.3503 - val_loss: 0.0884 - val_accuracy: 0.3750\n",
      "Epoch 9/200\n",
      "72/72 [==============================] - 75s 1s/step - loss: 0.0988 - accuracy: 0.3689 - val_loss: 0.0940 - val_accuracy: 0.3472\n",
      "Epoch 10/200\n",
      "72/72 [==============================] - 77s 1s/step - loss: 0.0969 - accuracy: 0.3806 - val_loss: 0.0871 - val_accuracy: 0.3628\n",
      "Epoch 11/200\n",
      "72/72 [==============================] - 74s 1s/step - loss: 0.0951 - accuracy: 0.3763 - val_loss: 0.0842 - val_accuracy: 0.3681\n",
      "Epoch 12/200\n",
      "72/72 [==============================] - 75s 1s/step - loss: 0.0935 - accuracy: 0.3845 - val_loss: 0.0848 - val_accuracy: 0.3872\n",
      "Epoch 13/200\n",
      "72/72 [==============================] - 74s 1s/step - loss: 0.0916 - accuracy: 0.3937 - val_loss: 0.0772 - val_accuracy: 0.4497\n",
      "Epoch 14/200\n",
      "72/72 [==============================] - 78s 1s/step - loss: 0.0889 - accuracy: 0.4093 - val_loss: 0.0783 - val_accuracy: 0.4132\n",
      "Epoch 15/200\n",
      "72/72 [==============================] - 76s 1s/step - loss: 0.0870 - accuracy: 0.4154 - val_loss: 0.0786 - val_accuracy: 0.4201\n",
      "Epoch 16/200\n",
      "72/72 [==============================] - 76s 1s/step - loss: 0.0872 - accuracy: 0.4206 - val_loss: 0.0781 - val_accuracy: 0.4149\n",
      "Epoch 17/200\n",
      "72/72 [==============================] - 76s 1s/step - loss: 0.0864 - accuracy: 0.4223 - val_loss: 0.0751 - val_accuracy: 0.4392\n",
      "Epoch 18/200\n",
      "72/72 [==============================] - 77s 1s/step - loss: 0.0843 - accuracy: 0.4275 - val_loss: 0.0739 - val_accuracy: 0.4253\n",
      "Epoch 19/200\n",
      "72/72 [==============================] - 121s 2s/step - loss: 0.0838 - accuracy: 0.4379 - val_loss: 0.0771 - val_accuracy: 0.4184\n",
      "Epoch 20/200\n",
      "72/72 [==============================] - 123s 2s/step - loss: 0.0815 - accuracy: 0.4462 - val_loss: 0.0709 - val_accuracy: 0.4514\n",
      "Epoch 21/200\n",
      "72/72 [==============================] - 124s 2s/step - loss: 0.0820 - accuracy: 0.4397 - val_loss: 0.0706 - val_accuracy: 0.4375\n",
      "Epoch 22/200\n",
      "72/72 [==============================] - 123s 2s/step - loss: 0.0785 - accuracy: 0.4557 - val_loss: 0.0699 - val_accuracy: 0.4201\n",
      "Epoch 23/200\n",
      "72/72 [==============================] - 122s 2s/step - loss: 0.0768 - accuracy: 0.4609 - val_loss: 0.0663 - val_accuracy: 0.4566\n",
      "Epoch 24/200\n",
      "72/72 [==============================] - 74s 1s/step - loss: 0.0754 - accuracy: 0.4605 - val_loss: 0.0630 - val_accuracy: 0.5295\n",
      "Epoch 25/200\n",
      "72/72 [==============================] - 75s 1s/step - loss: 0.0747 - accuracy: 0.4779 - val_loss: 0.0652 - val_accuracy: 0.4774\n",
      "Epoch 26/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0711 - accuracy: 0.4861 - val_loss: 0.0619 - val_accuracy: 0.4740\n",
      "Epoch 27/200\n",
      "72/72 [==============================] - 71s 993ms/step - loss: 0.0711 - accuracy: 0.4970 - val_loss: 0.0600 - val_accuracy: 0.5052\n",
      "Epoch 28/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0692 - accuracy: 0.5113 - val_loss: 0.0591 - val_accuracy: 0.5174\n",
      "Epoch 29/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0670 - accuracy: 0.5269 - val_loss: 0.0557 - val_accuracy: 0.5486\n",
      "Epoch 30/200\n",
      "72/72 [==============================] - 71s 989ms/step - loss: 0.0675 - accuracy: 0.5174 - val_loss: 0.0567 - val_accuracy: 0.5295\n",
      "Epoch 31/200\n",
      "72/72 [==============================] - 71s 988ms/step - loss: 0.0645 - accuracy: 0.5373 - val_loss: 0.0548 - val_accuracy: 0.5382\n",
      "Epoch 32/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0634 - accuracy: 0.5447 - val_loss: 0.0527 - val_accuracy: 0.5573\n",
      "Epoch 33/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0617 - accuracy: 0.5660 - val_loss: 0.0511 - val_accuracy: 0.5781\n",
      "Epoch 34/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0622 - accuracy: 0.5647 - val_loss: 0.0494 - val_accuracy: 0.5972\n",
      "Epoch 35/200\n",
      "72/72 [==============================] - 72s 999ms/step - loss: 0.0590 - accuracy: 0.5807 - val_loss: 0.0515 - val_accuracy: 0.5799\n",
      "Epoch 36/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0583 - accuracy: 0.5790 - val_loss: 0.0507 - val_accuracy: 0.6024\n",
      "Epoch 37/200\n",
      "72/72 [==============================] - 72s 999ms/step - loss: 0.0563 - accuracy: 0.5994 - val_loss: 0.0461 - val_accuracy: 0.5712\n",
      "Epoch 38/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0539 - accuracy: 0.6059 - val_loss: 0.0445 - val_accuracy: 0.5833\n",
      "Epoch 39/200\n",
      "72/72 [==============================] - 75s 1s/step - loss: 0.0523 - accuracy: 0.6159 - val_loss: 0.0420 - val_accuracy: 0.6233\n",
      "Epoch 40/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0503 - accuracy: 0.6181 - val_loss: 0.0432 - val_accuracy: 0.5972\n",
      "Epoch 41/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0503 - accuracy: 0.6228 - val_loss: 0.0449 - val_accuracy: 0.5816\n",
      "Epoch 42/200\n",
      "72/72 [==============================] - 72s 999ms/step - loss: 0.0504 - accuracy: 0.6315 - val_loss: 0.0419 - val_accuracy: 0.6632\n",
      "Epoch 43/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0479 - accuracy: 0.6432 - val_loss: 0.0404 - val_accuracy: 0.6632\n",
      "Epoch 44/200\n",
      "72/72 [==============================] - 72s 996ms/step - loss: 0.0462 - accuracy: 0.6545 - val_loss: 0.0362 - val_accuracy: 0.6806\n",
      "Epoch 45/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0435 - accuracy: 0.6688 - val_loss: 0.0314 - val_accuracy: 0.6806\n",
      "Epoch 46/200\n",
      "72/72 [==============================] - 71s 988ms/step - loss: 0.0430 - accuracy: 0.6814 - val_loss: 0.0358 - val_accuracy: 0.6493\n",
      "Epoch 47/200\n",
      "72/72 [==============================] - 71s 988ms/step - loss: 0.0435 - accuracy: 0.6784 - val_loss: 0.0325 - val_accuracy: 0.6823\n",
      "Epoch 48/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0408 - accuracy: 0.6810 - val_loss: 0.0330 - val_accuracy: 0.6649\n",
      "Epoch 49/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0402 - accuracy: 0.6853 - val_loss: 0.0328 - val_accuracy: 0.6875\n",
      "Epoch 50/200\n",
      "72/72 [==============================] - 75s 1s/step - loss: 0.0395 - accuracy: 0.6901 - val_loss: 0.0286 - val_accuracy: 0.6892\n",
      "Epoch 51/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0371 - accuracy: 0.7040 - val_loss: 0.0328 - val_accuracy: 0.6753\n",
      "Epoch 52/200\n",
      "72/72 [==============================] - 76s 1s/step - loss: 0.0361 - accuracy: 0.7066 - val_loss: 0.0248 - val_accuracy: 0.7222\n",
      "Epoch 53/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0358 - accuracy: 0.7205 - val_loss: 0.0324 - val_accuracy: 0.6753\n",
      "Epoch 54/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0379 - accuracy: 0.7114 - val_loss: 0.0288 - val_accuracy: 0.6892\n",
      "Epoch 55/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0350 - accuracy: 0.7183 - val_loss: 0.0252 - val_accuracy: 0.7014\n",
      "Epoch 56/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0345 - accuracy: 0.7201 - val_loss: 0.0262 - val_accuracy: 0.7101\n",
      "Epoch 57/200\n",
      "72/72 [==============================] - 71s 990ms/step - loss: 0.0340 - accuracy: 0.7205 - val_loss: 0.0263 - val_accuracy: 0.6979\n",
      "Epoch 58/200\n",
      "72/72 [==============================] - 75s 1s/step - loss: 0.0322 - accuracy: 0.7396 - val_loss: 0.0245 - val_accuracy: 0.7031\n",
      "Epoch 59/200\n",
      "72/72 [==============================] - 72s 997ms/step - loss: 0.0304 - accuracy: 0.7435 - val_loss: 0.0214 - val_accuracy: 0.7309\n",
      "Epoch 60/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0282 - accuracy: 0.7517 - val_loss: 0.0198 - val_accuracy: 0.7535\n",
      "Epoch 61/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0285 - accuracy: 0.7591 - val_loss: 0.0225 - val_accuracy: 0.7135\n",
      "Epoch 62/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0292 - accuracy: 0.7543 - val_loss: 0.0200 - val_accuracy: 0.7483\n",
      "Epoch 63/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0257 - accuracy: 0.7730 - val_loss: 0.0188 - val_accuracy: 0.7691\n",
      "Epoch 64/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0265 - accuracy: 0.7782 - val_loss: 0.0200 - val_accuracy: 0.7535\n",
      "Epoch 65/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0252 - accuracy: 0.7778 - val_loss: 0.0179 - val_accuracy: 0.7622\n",
      "Epoch 66/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0252 - accuracy: 0.7869 - val_loss: 0.0175 - val_accuracy: 0.7361\n",
      "Epoch 67/200\n",
      "72/72 [==============================] - 72s 998ms/step - loss: 0.0249 - accuracy: 0.7834 - val_loss: 0.0168 - val_accuracy: 0.7795\n",
      "Epoch 68/200\n",
      "72/72 [==============================] - 72s 998ms/step - loss: 0.0252 - accuracy: 0.7865 - val_loss: 0.0177 - val_accuracy: 0.7691\n",
      "Epoch 69/200\n",
      "72/72 [==============================] - 72s 1s/step - loss: 0.0237 - accuracy: 0.7899 - val_loss: 0.0148 - val_accuracy: 0.7812\n",
      "Epoch 70/200\n",
      "72/72 [==============================] - 72s 997ms/step - loss: 0.0223 - accuracy: 0.7947 - val_loss: 0.0141 - val_accuracy: 0.7691\n",
      "Epoch 71/200\n",
      "72/72 [==============================] - 72s 997ms/step - loss: 0.0213 - accuracy: 0.8034 - val_loss: 0.0141 - val_accuracy: 0.7917\n",
      "Epoch 72/200\n",
      "72/72 [==============================] - 73s 1s/step - loss: 0.0213 - accuracy: 0.8142 - val_loss: 0.0144 - val_accuracy: 0.7743\n",
      "Epoch 73/200\n",
      "72/72 [==============================] - 72s 999ms/step - loss: 0.0202 - accuracy: 0.8151 - val_loss: 0.0152 - val_accuracy: 0.7604\n",
      "Epoch 74/200\n",
      "72/72 [==============================] - 78s 1s/step - loss: 0.0202 - accuracy: 0.8043 - val_loss: 0.0151 - val_accuracy: 0.7639\n",
      "Epoch 75/200\n",
      "72/72 [==============================] - 86s 1s/step - loss: 0.0193 - accuracy: 0.8212 - val_loss: 0.0125 - val_accuracy: 0.7882\n",
      "Epoch 76/200\n",
      "72/72 [==============================] - 90s 1s/step - loss: 0.0193 - accuracy: 0.8112 - val_loss: 0.0120 - val_accuracy: 0.7795\n",
      "Epoch 77/200\n",
      "72/72 [==============================] - 90s 1s/step - loss: 0.0198 - accuracy: 0.8186 - val_loss: 0.0128 - val_accuracy: 0.7934\n",
      "Epoch 78/200\n",
      "72/72 [==============================] - 98s 1s/step - loss: 0.0191 - accuracy: 0.8277 - val_loss: 0.0118 - val_accuracy: 0.7899\n",
      "Epoch 79/200\n",
      "72/72 [==============================] - 101s 1s/step - loss: 0.0207 - accuracy: 0.8025 - val_loss: 0.0106 - val_accuracy: 0.8194\n",
      "Epoch 80/200\n",
      "72/72 [==============================] - 93s 1s/step - loss: 0.0173 - accuracy: 0.8194 - val_loss: 0.0117 - val_accuracy: 0.8073\n",
      "Epoch 81/200\n",
      "72/72 [==============================] - 93s 1s/step - loss: 0.0171 - accuracy: 0.8333 - val_loss: 0.0105 - val_accuracy: 0.7969\n",
      "Epoch 82/200\n",
      "72/72 [==============================] - 90s 1s/step - loss: 0.0160 - accuracy: 0.8355 - val_loss: 0.0098 - val_accuracy: 0.8003\n",
      "Epoch 83/200\n",
      "72/72 [==============================] - 105s 1s/step - loss: 0.0152 - accuracy: 0.8394 - val_loss: 0.0081 - val_accuracy: 0.8003\n",
      "Epoch 84/200\n",
      "72/72 [==============================] - 85s 1s/step - loss: 0.0148 - accuracy: 0.8390 - val_loss: 0.0080 - val_accuracy: 0.7969\n",
      "Epoch 85/200\n",
      "72/72 [==============================] - 90s 1s/step - loss: 0.0139 - accuracy: 0.8368 - val_loss: 0.0089 - val_accuracy: 0.8090\n",
      "Epoch 86/200\n",
      "72/72 [==============================] - 99s 1s/step - loss: 0.0136 - accuracy: 0.8359 - val_loss: 0.0090 - val_accuracy: 0.8021\n",
      "Epoch 87/200\n",
      "72/72 [==============================] - 97s 1s/step - loss: 0.0164 - accuracy: 0.8333 - val_loss: 0.0109 - val_accuracy: 0.8038\n",
      "Epoch 88/200\n",
      "72/72 [==============================] - 110s 2s/step - loss: 0.0156 - accuracy: 0.8351 - val_loss: 0.0092 - val_accuracy: 0.8090\n",
      "Epoch 89/200\n",
      "72/72 [==============================] - 106s 1s/step - loss: 0.0150 - accuracy: 0.8368 - val_loss: 0.0110 - val_accuracy: 0.7778\n",
      "Epoch 90/200\n",
      "72/72 [==============================] - 90s 1s/step - loss: 0.0152 - accuracy: 0.8273 - val_loss: 0.0082 - val_accuracy: 0.8351\n",
      "Epoch 91/200\n",
      "72/72 [==============================] - 90s 1s/step - loss: 0.0150 - accuracy: 0.8416 - val_loss: 0.0074 - val_accuracy: 0.7951\n",
      "Epoch 92/200\n",
      "72/72 [==============================] - 109s 2s/step - loss: 0.0123 - accuracy: 0.8459 - val_loss: 0.0073 - val_accuracy: 0.8125\n",
      "Epoch 93/200\n",
      "72/72 [==============================] - 123s 2s/step - loss: 0.0120 - accuracy: 0.8403 - val_loss: 0.0058 - val_accuracy: 0.8229\n",
      "Epoch 94/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.8451"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a1327d1db106>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1212\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1214\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1215\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 100\n",
    "cb = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0.0001, patience=10)\n",
    "\n",
    "history = model.fit(train_set, epochs=NUM_EPOCHS, validation_data=test_set, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /sm/classify_model\\assets\n",
      "INFO:tensorflow:Assets written to: /sm/classify_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"/sm/classify_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function for inferrence\n",
    "def treatinput(inp):\n",
    "    # Make string into lowercase string\n",
    "    treated = inp.lower()\n",
    "    # remove punctuation\n",
    "    treated = treated.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    # remove trailing whitespace\n",
    "    treated = treated.strip()\n",
    "    # Remove stopwords\n",
    "    treated = stopword.remove(treated)\n",
    "    # Stem string\n",
    "    treated = stemmer.stem(treated)\n",
    "    return treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "oknum polisi polsek sukajadi pungli\n"
     ]
    }
   ],
   "source": [
    "# sample inferrece\n",
    "sample_laporan = \"Oknum polisi di polsek sukajadi melakukan pungli\"\n",
    "treated_input = treatinput(sample_laporan)\n",
    "print(treated_input)\n",
    "pad = pad_sequences(tokenizer.texts_to_sequences([treated_input]), maxlen=max_length, truncating=trunc_type)\n",
    "prediction = model.predict(pad)\n",
    "\n",
    "res = dict(zip(label_list, prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "perselisihan 0.00000\ninfrastruktur 0.00008\npemerintah 0.00020\nkesehatan 0.00099\nteknologi 0.00000\nadministrasi 0.00167\nfasilitas 0.00000\nlingkungan 0.00000\nketertiban 0.00000\nlistrik 0.00000\nbahaya 0.00000\nlainnya 0.00000\npungli 0.90029\nilegal 0.00000\nlalulintas 0.00000\nbencana 0.00000\nair 0.00000\npendidikan 0.00000\nkebersihan 0.00000\nsosial 0.00000\nwisata 0.00000\nsara 0.00000\npencurian 0.00000\nkorupsi 0.00010\nbbm 0.00000\nkeuangan 0.00157\n"
     ]
    }
   ],
   "source": [
    "# Print predictions\n",
    "for i in res.keys():\n",
    "    # if(res[i] > 0.6):\n",
    "    print(\"{} {:.5f}\".format(i, res[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a new model with Keras Tuner // CAREFUL THIS TAKES A LONG TIME\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "def model_builder(hp):\n",
    "    emb_units = hp.Int('emb_units', min_value=16, max_value=256, step=16)\n",
    "    bid1_units = hp.Int('bid1_units', min_value=16, max_value=256, step=16)\n",
    "    drop1_frac = hp.Float('drop1_frac', min_value=0.1, max_value=0.8, step=0.1)\n",
    "    bid2_units = hp.Int('bid2_units', min_value=16, max_value=256, step=16)\n",
    "    drop2_frac = hp.Float('drop2_frac', min_value=0.1, max_value=0.8, step=0.1)\n",
    "    dense1_units = hp.Int('dense1_unit', min_value=16, max_value=256, step=16)\n",
    "    drop3_frac = hp.Float('drop3_frac', min_value=0.1, max_value=0.8, step=0.1)\n",
    "    dense2_units = hp.Int('dense2_unit', min_value=16, max_value=256, step=16)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, emb_units),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(bid1_units, return_sequences=True)),\n",
    "    tf.keras.layers.Dropout(drop1_frac),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(bid2_units)),\n",
    "    tf.keras.layers.Dropout(drop2_frac),\n",
    "    tf.keras.layers.Dense(dense1_units, activation='relu'),\n",
    "    tf.keras.layers.Dropout(drop3_frac),\n",
    "    tf.keras.layers.Dense(dense2_units, activation='relu'),\n",
    "    tf.keras.layers.Dense(26, activation='sigmoid')\n",
    "])\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder, objective='val_accuracy', max_epochs=100, factor=3, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_set, epochs=100, validation_data=test_set, callbacks=[stop_early])\n",
    "\n",
    "best_hps= tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps)"
   ]
  },
  {
   "source": [
    "# Trial 5 Complete [00h 03m 30s]\n",
    "# val_accuracy: 0.2395833283662796\n",
    "\n",
    "# Best val_accuracy So Far: 0.2534722089767456\n",
    "# Total elapsed time: 00h 55m 20s\n",
    "\n",
    "# Search: Running Trial #6\n",
    "\n",
    "# Hyperparameter    |Value             |Best Value So Far \n",
    "# emb_units         |48                |32                \n",
    "# bid1_units        |240               |112               \n",
    "# drop1_frac        |0.6               |0.3               \n",
    "# bid2_units        |176               |112               \n",
    "# drop2_frac        |0.4               |0.4               \n",
    "# dense1_unit       |176               |112               \n",
    "# drop3_frac        |0.7               |0.4               \n",
    "# dense2_unit       |144               |224               \n",
    "# learning_rate     |1e-05             |0.01              \n",
    "# tuner/epochs      |2                 |2                 \n",
    "# tuner/initial_e...|0                 |0                 \n",
    "# tuner/bracket     |2                 |2                 \n",
    "# tuner/round       |0                 |0                 \n",
    "\n",
    "# Epoch 1/2\n",
    "# 72/72 [==============================] - 618s 8s/step - loss: 0.6918 - accuracy: 0.0573 - val_loss: 0.6889 - val_accuracy: 0.0625\n",
    "# Epoch 2/2\n",
    "# 72/72 [==============================] - 623s 9s/step - loss: 0.6846 - accuracy: 0.0760 - val_loss: 0.6749 - val_accuracy: 0.0521"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t = tuner.hypermodel.build(best_hps)\n",
    "history = model_t.fit(dataset, epochs=100, validation_data=test_set)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(dataset, epochs=best_epoch, validation_data=test_set)"
   ]
  }
 ]
}